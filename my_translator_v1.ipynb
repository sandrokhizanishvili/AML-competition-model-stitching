{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f4e76a",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c464e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059267f6",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed10bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation functions\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load processed data from .npz file\"\"\"\n",
    "    data = dict(np.load(path, allow_pickle=True))\n",
    "    # data['caption2img'] = data['caption2img'].item()\n",
    "    # data['caption2img_idx'] = data['caption2img_idx'].item()\n",
    "    return data\n",
    "\n",
    "def prepare_train_data(data):\n",
    "    \"\"\"Prepare training data from loaded dict\"\"\"\n",
    "    caption_embd = data['captions/embeddings']\n",
    "    image_embd = data['images/embeddings']\n",
    "    # Map caption embeddings to corresponding image embeddings\n",
    "    label = data['captions/label'] # N x M\n",
    "\n",
    "    # repeat the image embeddings according to the label\n",
    "    label_idx = np.nonzero(label)[1]\n",
    "    print(label_idx.shape)\n",
    "    image_embd = image_embd[label_idx]\n",
    "    assert caption_embd.shape[0] == image_embd.shape[0], \"Mismatch in number of caption and image embeddings\"\n",
    "\n",
    "    X = torch.from_numpy(caption_embd).float()\n",
    "    # Map each caption to its corresponding image embedding\n",
    "    y = torch.from_numpy(image_embd).float()\n",
    "    label = torch.from_numpy(label).bool()\n",
    "\n",
    "    print(f\"Train data: {len(X)} captions, {len(image_embd)} images\")\n",
    "    return X, y, label\n",
    "\n",
    "def generate_submission(sample_ids, translated_embeddings, output_file=\"submission.csv\"):\n",
    "    \"\"\"\n",
    "    Generate a submission.csv file from translated embeddings.\n",
    "    \"\"\"\n",
    "    print(\"Generating submission file...\")\n",
    "\n",
    "    if isinstance(translated_embeddings, torch.Tensor):\n",
    "        translated_embeddings = translated_embeddings.cpu().numpy()\n",
    "\n",
    "    # Create a DataFrame with sample_id and embeddings\n",
    "\n",
    "    df_submission = pd.DataFrame({'id': sample_ids, 'embedding': translated_embeddings.tolist()})\n",
    "\n",
    "    df_submission.to_csv(output_file, index=False, float_format='%.17g')\n",
    "    print(f\"✓ Saved submission to {output_file}\")\n",
    "    \n",
    "    return df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "500004ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training functions\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, epochs, lr, MODEL_PATH):\n",
    "    \"\"\"Train the MLP model\"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "\n",
    "            loss = F.mse_loss(outputs, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = F.mse_loss(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            Path(MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"  ✓ Saved best model (val_loss={val_loss:.6f})\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba2473",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb427dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = load_data('data/train/train/train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbcd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000,)\n",
      "Train data: 125000 captions, 125000 images\n"
     ]
    }
   ],
   "source": [
    "# prepare train data\n",
    "X, y, label = prepare_train_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ecc9634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([125000, 1024]), torch.Size([125000, 1536]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e7cfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([112500, 1024]),\n",
       " torch.Size([12500, 1024]),\n",
       " torch.Size([112500, 1536]),\n",
       " torch.Size([12500, 1536]),\n",
       " torch.Size([112500, 25000]),\n",
       " torch.Size([12500, 25000]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train and val\n",
    "DATASET_SIZE = len(X)\n",
    "n_train = int(0.9 * len(X))\n",
    "TRAIN_SPLIT = torch.zeros(len(X), dtype=torch.bool)\n",
    "TRAIN_SPLIT[:n_train] = 1\n",
    "X_train, X_val = X[TRAIN_SPLIT], X[~TRAIN_SPLIT]\n",
    "y_train, y_val = y[TRAIN_SPLIT], y[~TRAIN_SPLIT]\n",
    "labels_train, labels_val = label[TRAIN_SPLIT], label[~TRAIN_SPLIT]\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape, labels_train.shape, labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae842923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "\n",
    "# standardize targets\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_val_scaled = scaler_y.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56cc9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers as a pickle file\n",
    "with open('scaler_X.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_X, f)\n",
    "\n",
    "with open('scaler_y.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac1efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save original train/val data and labels\n",
    "torch.save({'captions/embeddings': X_train, 'images/embeddings': y_train, 'captions/label': labels_train}, 'data/X_y_labels_train.pt')\n",
    "torch.save({'captions/embeddings': X_val, 'images/embeddings': y_val, 'captions/label': labels_val}, 'data/X_y_labels_val.pt')\n",
    "\n",
    "# save scaled train/val data\n",
    "torch.save({'captions/embeddings_standartized': torch.from_numpy(X_train_scaled).float(), 'images/embeddings_standartized': torch.from_numpy(y_train_scaled).float(), 'captions/label': labels_train}, 'data/X_y_labels_train_scaled.pt')\n",
    "torch.save({'captions/embeddings_standartized': torch.from_numpy(X_val_scaled).float(), 'images/embeddings_standartized': torch.from_numpy(y_val_scaled).float(), 'captions/label': labels_val}, 'data/X_y_labels_val_scaled.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad91914",
   "metadata": {},
   "source": [
    "*Read Data Back*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78620b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read scaled data back\n",
    "train = torch.load('data/X_y_labels_train_scaled.pt')\n",
    "val = torch.load('data/X_y_labels_val_scaled.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6adf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'captions/embeddings_standartized': tensor([[-1.0484, -0.2398, -1.1937,  ...,  1.9227, -0.8140,  0.6990],\n",
       "         [ 0.5970, -1.0902, -1.0971,  ...,  0.5235, -0.6814,  0.5296],\n",
       "         [-0.8602, -0.6004, -1.7190,  ..., -0.0170,  0.2435, -0.2536],\n",
       "         ...,\n",
       "         [ 0.7032, -0.8866, -0.9816,  ..., -0.3574,  1.2990, -1.6193],\n",
       "         [ 1.9398, -1.4414, -0.8151,  ...,  1.1098,  1.5640, -1.2967],\n",
       "         [ 0.5412, -1.3856, -2.1370,  ...,  1.5716,  1.2756,  0.0366]]),\n",
       " 'images/embeddings_standartized': tensor([[-1.0878, -1.4801, -0.0469,  ...,  0.5059,  0.0360,  2.7207],\n",
       "         [-1.0878, -1.4801, -0.0469,  ...,  0.5059,  0.0360,  2.7207],\n",
       "         [-1.0878, -1.4801, -0.0469,  ...,  0.5059,  0.0360,  2.7207],\n",
       "         ...,\n",
       "         [-1.5101,  1.4579,  1.0158,  ...,  0.5842, -1.9490,  1.4042],\n",
       "         [-1.5101,  1.4579,  1.0158,  ...,  0.5842, -1.9490,  1.4042],\n",
       "         [-1.5101,  1.4579,  1.0158,  ...,  0.5842, -1.9490,  1.4042]]),\n",
       " 'captions/label': tensor([[ True, False, False,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "736d67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = train['captions/embeddings_standartized']\n",
    "y_train_scaled = train['images/embeddings_standartized']\n",
    "labels_train = train['captions/label']\n",
    "\n",
    "\n",
    "X_val_scaled = val['captions/embeddings_standartized']\n",
    "y_val_scaled = val['images/embeddings_standartized']\n",
    "labels_val = val['captions/label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff962bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, val\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c242d",
   "metadata": {},
   "source": [
    "*Make Padding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96fccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate padding needed\n",
    "padding_needed = 1536 - 1024  # This is 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "043b5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = F.pad(X_train_scaled, (0, padding_needed))\n",
    "X_val_scaled = F.pad(X_val_scaled, (0, padding_needed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([112500, 1536]), torch.Size([12500, 1536]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape, X_val_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f3c14",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "008f41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_PATH = \"models/mlp_v1.pth\"\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=1536, output_dim=1536, hidden_dim=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # nn.Linear(input_dim, output_dim),\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a6d5981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Parameters: 6,295,040\n",
      "\n",
      "3. Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 440/440 [01:11<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.791533, Val Loss = 0.781824\n",
      "  ✓ Saved best model (val_loss=0.781824)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 440/440 [01:28<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.748296, Val Loss = 0.770284\n",
      "  ✓ Saved best model (val_loss=0.770284)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 440/440 [00:43<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.730276, Val Loss = 0.765619\n",
      "  ✓ Saved best model (val_loss=0.765619)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 440/440 [00:40<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.717556, Val Loss = 0.763948\n",
      "  ✓ Saved best model (val_loss=0.763948)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 440/440 [00:43<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.707239, Val Loss = 0.763132\n",
      "  ✓ Saved best model (val_loss=0.763132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 440/440 [00:46<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.698404, Val Loss = 0.762343\n",
      "  ✓ Saved best model (val_loss=0.762343)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 440/440 [00:42<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.690626, Val Loss = 0.763222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 440/440 [01:19<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.683179, Val Loss = 0.764550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 440/440 [00:40<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.676641, Val Loss = 0.765372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 440/440 [00:39<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.670239, Val Loss = 0.767353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 440/440 [01:21<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss = 0.664453, Val Loss = 0.768423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 440/440 [01:15<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss = 0.658855, Val Loss = 0.771243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 440/440 [00:42<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss = 0.653620, Val Loss = 0.772506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 440/440 [00:42<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss = 0.648486, Val Loss = 0.772450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 440/440 [00:48<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss = 0.643483, Val Loss = 0.777190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 440/440 [00:44<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss = 0.638990, Val Loss = 0.778562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 440/440 [00:44<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss = 0.634541, Val Loss = 0.779180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 440/440 [00:42<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss = 0.630257, Val Loss = 0.781181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 440/440 [00:43<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss = 0.626201, Val Loss = 0.784228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 440/440 [00:43<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss = 0.622398, Val Loss = 0.783102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = MLP().to(DEVICE)\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_scaled, y_train_scaled), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_scaled, y_val_scaled), batch_size=BATCH_SIZE)\n",
    "X_train_scaled.shape, X_val_scaled.shape\n",
    "\n",
    "# Train\n",
    "print(\"\\n3. Training...\")\n",
    "model = train_model(model, train_loader, val_loader, DEVICE, EPOCHS, LR, MODEL_PATH)\n",
    "\n",
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d25026",
   "metadata": {},
   "source": [
    "# Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read scaler for features\n",
    "with open('scaler_X.pkl', 'rb') as f:\n",
    "    sc_x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a27ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7d3778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission file...\n",
      "✓ Saved submission to submissions/submission_v1.csv\n",
      "Model saved to: models/mlp_v1.pth\n"
     ]
    }
   ],
   "source": [
    "test_data = load_data(\"data/test/test/test.clean.npz\")\n",
    "\n",
    "test_embds = test_data['captions/embeddings']\n",
    "test_embds = sc_x.transform(test_embds) # Scale the test caption embeddings\n",
    "test_embds = torch.from_numpy(test_embds).float()\n",
    "# padding_needed = 1536 - 1024  # This is 512\n",
    "test_embds = F.pad(test_embds, (0, padding_needed)) # make zero padding\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_embds = model(test_embds.to(DEVICE)).cpu()\n",
    "\n",
    "submission = generate_submission(test_data['captions/ids'], pred_embds, 'submissions/submission_v1.csv')\n",
    "print(f\"Model saved to: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e6a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec8d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826f61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f2223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715091fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86201efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e70d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdc01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26209e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4527952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
